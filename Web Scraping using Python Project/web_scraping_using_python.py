# -*- coding: utf-8 -*-
"""Web Scraping using Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tMIjYQB6XKoZDfRTXWjQgI4WS5-B_tC1

## **Basic Web Scraping Using Python**
"""

import requests
from bs4 import BeautifulSoup

# Step 1: Define the website URL
BASE_URL = "https://quotes.toscrape.com/"

# Step 2: Send a GET request to the website to download the HTML
response = requests.get(BASE_URL, timeout=15)
response.raise_for_status()

# Step 3: Parse the HTML using BeautifulSoup
soup = BeautifulSoup(response.text, "html.parser")

# Step 4: Create a list to store all extracted quotes
data = []

# Step 5: Find all quote blocks on the page (each quote is inside <div class="quote">)
for quote_block in soup.select("div.quote"):

  # Extract the quote text (inside <span class="text">)
  quote_text = quote_block.select_one("span.text").get_text(strip=True)

  # Extract the author name (inside <small class="author">)
  author_name = quote_block.select_one("small.author").get_text(strip=True)

  # Extract all tags (each tag is in <a class="tag"> inside <div class="tags">)
  tag_elements = quote_block.select("div.tags a.tag") # list of all <a> tag elements
  tags_list = [tag.get_text(strip=True) for tag in tag_elements]

  # Save this quote as a dictionary
  data.append({
      "quote": quote_text,
      "author": author_name,
      "tags": tags_list
  })

# Step 6: Print results to confirm
print(f"Collected {len(data)} quotes from the first page.\n")

# Show the first extracted quote to verify the data structure
print("Example of the extracted data:")
print(data[0])

print("Example of the extracted data:")
print(data[1])

