# -*- coding: utf-8 -*-
"""hackernews_scraper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8QwwBd5R7BD3yDTYKdjXXbcA18Lqt70

## **Hacker News Data Extraction with Web Scraping in Python**
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

BASE = "https://news.ycombinator.com/"

# Step 1: Download the front page HTML
resp = requests.get(BASE, timeout=15, headers={"User-Agent": "learning-scraper/1.0"})
resp.raise_for_status
soup = BeautifulSoup(resp.text, "html.parser")

items = []

# Step 2: Each story headline sits in a row: <tr class="athing">
for story in soup.select("tr.athing"):
  # To get the headline information
  rank_el = story.select_one(".rank")
  title_el = story.select_one(".titleline a")
  site_el = story.select_one(".sitestr")

  rank = int(rank_el.get_text(strip=True).rstrip(".")) if rank_el else None
  title = title_el.get_text(strip=True) if title_el else None
  link = urljoin(BASE, title_el["href"]) if title_el and title_el.has_attr("href") else None
  site = site_el.get_text(strip=True) if site_el else None

  # The next row contains the "subtext" (score, author, age, comments)
  subtext = story.find_next_sibling("tr").select_one(".subtext")
  if subtext:
    score_el = subtext.select_one(".score")
    author_el = subtext.select_one(".hnuser")
    age_el = subtext.select_one(".age")
    comment_links = subtext.select_one("a")

    score = None
    if score_el:
      # "123 points" -> 123
      try:
        score = int(score_el.get_text(strip=True).split()[0])
      except Exception:
        score = None

    author = author_el.get_text(strip=True) if author_el else None
    age = age_el.get_text(strip=True) if age_el else None

    # comments is usually the last <a> in subtext (e.g., "45 comments" or "discuss")
    comments = None
    if comment_links and isinstance(comment_links, list):
      last_text = comment_links[-1].get_text(strip=True)
      if "comment" in last_text:
        try:
          comments = int(last_text.split()[0])
        except Exception:
          comments = 0
      else:
        comments = 0
    else:
      comments = 0

  else:
    score = None
    author = None
    age = None
    comments = 0

  # Save this quote as a dictionary
  items.append({
        "rank": rank,
        "title": title,
        "link": link,
        "site": site,
        "score": score,
        "author": author,
        "age": age,
        "comments": comments
    })

# Step 3: Print results to confirm
print(f"Collected {len(items)} stories from the front page.")
print(items[0])

print(items[1])

print(items[2])

