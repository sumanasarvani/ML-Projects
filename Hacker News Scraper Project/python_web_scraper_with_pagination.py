# -*- coding: utf-8 -*-
"""Python Web Scraper with Pagination.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TMmdhnnebttipYF5XzIQZUUsooDDsVvf

## **Python Web Scraper for Hacker News Stories (with Pagination)**
"""

import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlencode

BASE = "https://news.ycombinator.com/"
headers = {"User-Agent": "learning-scraper/1.0"}

from os import setgroups
def fetch_page(page: int):
  params = {"p": page} if page > 1 else {}
  url = BASE + ("news?" + urlencode(params) if params else "")

  r = requests.get(url, headers = headers, timeout=15)
  r.raise_for_status

  soup = BeautifulSoup(r.text, "html.parser")
  results = []

  for story in soup.select("tr.athing"):

        # Extract rank, title, link, site
        rank_el = story.select_one(".rank")
        title_el = story.select_one(".titleline a")
        site_el = story.select_one(".sitestr")  # optional (may not exist)

        rank = int(rank_el.get_text(strip=True).rstrip(".")) if rank_el else None
        title = title_el.get_text(strip=True) if title_el else None
        link = urljoin(BASE, title_el["href"]) if title_el and title_el.has_attr("href") else None
        site = site_el.get_text(strip=True) if site_el else None

        # The next table row contains subtext: score, author, age, comments
        subtext = story.find_next_sibling("tr").select_one(".subtext")

        score = author = age = None
        comments = 0  # default to 0 if no comments found

        if subtext:
            # Extract individual elements
            score_el = subtext.select_one(".score")
            author_el = subtext.select_one(".hnuser")
            age_el = subtext.select_one(".age")
            comment_links = subtext.select("a")  # list of <a> links in subtext

            # Parse score: e.g. "123 points" â†’ 123
            if score_el:
                try:
                    score = int(score_el.get_text(strip=True).split()[0])
                except Exception:
                    score = None

            # Parse author and age if available
            author = author_el.get_text(strip=True) if author_el else None
            age = age_el.get_text(strip=True) if age_el else None

            # Parse comments from last <a> (e.g. "42 comments", "discuss")
            if comment_links:
                last_text = comment_links[-1].get_text(strip=True)
                if "comment" in last_text:  # e.g. "42 comments"
                    try:
                        comments = int(last_text.split()[0])
                    except Exception:
                        comments = 0  # error fallback

        # Store extracted data for this story
        results.append({
            "rank": rank,
            "title": title,
            "link": link,
            "site": site,
            "score": score,
            "author": author,
            "Time of post": age,
            "comments": comments,
            "page": page,
        })

  return results

all_items = []
for p in range(1, 4):
    page_items = fetch_page(p)
    print(f"Page {p}: {len(page_items)} stories")  # Show how many stories found
    all_items.extend(page_items)  # Add all stories to master list
    time.sleep(0.75)  # Pause to avoid hitting server too quickly

print(f"Total stories: {len(all_items)}")

page_items = fetch_page(1)
print(page_items[0])

print(page_items[1])

